# Privacy-Preserving Content-Based Image Retrieval
## Complete Presentation with Verbatim Speaker Scripts

---

# SLIDE 1: Title

## Slide Content:
```
Privacy-Preserving Content-Based Image Retrieval:
Cryptographic Foundations for Secure Cloud-Aided Similarity Search

Eng: Ahmed Mohamed Elsayed
```

## The Script:

"Good [morning/afternoon], everyone. Thank you for your time today.

My name is Ahmed Mohamed Elsayed, and I will be presenting my PhD research on **Privacy-Preserving Content-Based Image Retrieval** — specifically, the cryptographic foundations that enable secure similarity search in cloud environments.

[PAUSE — 2 seconds]

Over the next [X] minutes, I will walk you through **two** core encryption approaches I have been investigating: first, a scheme called ASPE, and then, a more robust construction based on the Learning With Errors problem. I will also share where my current research stands and the specific technical challenges I am working to solve.

[PAUSE — look at audience]

Let's begin."

**[CLICK to next slide]**

---

## SLIDE 2: Problem Setting

## Slide Content:

```
Problem Setting:
• Cloud-based image retrieval requires outsourcing feature vectors to untrusted servers
• Server must perform approximate nearest neighbor (ANN) search without learning:
   - Content of stored images
   - Content of user queries
   - Similarity relationships between database entries

Research Focus:
• Secure Cloud-Aided Approximate Nearest Neighbor Search
• Core challenge: Enabling distance-preserving operations in the encrypted domain
```

## The Script:

"So, what problem are we trying to solve?

[PAUSE]

Imagine you have a large collection of images — perhaps millions — and you want to store them in the cloud so users can search for visually similar images. The challenge is this: the cloud server is **untrusted**. We cannot assume it will protect our data.

[PAUSE — gesture toward slide]

Specifically, we need the server to perform similarity search — what we call **approximate nearest neighbor search** — **without** learning three things:

First, the actual content of the stored images.
Second, the content of user queries.
And third, even the similarity relationships *between* images in the database.

[PAUSE]

This is the core of my research: enabling **distance-preserving operations** — the computations needed for similarity search — to happen entirely in the **encrypted domain**.

[PAUSE — transition voice]

Now, before we discuss encryption, we need to understand **what** we are encrypting. Let me show you the feature representation I am working with."

**[CLICK to next slide]**

---

# SLIDE 3: CLIP Embeddings

## Slide Content:

```
Contrastive Language-Image Pre-training (CLIP):
• Produces semantically rich d-dimensional feature vectors (d = 512 or 768)
• Vectors are L2-normalized: ||p||₂ = 1

Similarity Measure:
• For normalized vectors, cosine similarity equals inner product:

   sim(p, q) = cos(θ) = (p · q) / (||p|| ||q||) = p · q

Implication:
• Secure similarity search requires preserving inner product relationships
```

## The Script:

"The feature representation I am using is called **CLIP** — Contrastive Language-Image Pre-training.

CLIP is a neural network that takes an image and produces a **high-dimensional vector** — typically 512 or 768 dimensions — that captures the **semantic content** of that image.

[PAUSE]

Now, here is a crucial property: CLIP vectors are **normalized**. Their length is always equal to one.

[PAUSE — point to formula]

Why does this matter? Because for normalized vectors, **cosine similarity** — the standard measure for comparing images — simplifies to just the **dot product**. You can see the formula here: the denominator becomes one, so we are left with simply **p dot q**.

[PAUSE]

This is important because it tells us exactly what our encryption scheme needs to do. If we want to compare images securely, we need an encryption method that **preserves inner product relationships** in the encrypted domain.

[PAUSE — transition voice]

Now, before we jump into encryption, I want to show you how both **cosine similarity** and **Euclidean k-nearest-neighbor search** can be mapped to the same primitive: the **dot product**."

**[CLICK to next slide]**

---

# SLIDE 4: Dot Product = The Core Computation Primitive

## Slide Content:

```
Dot Product (Inner Product):
• Given vectors x, q ∈ ℝᵈ:
     x · q =  Σᵢ xᵢ qᵢ

Interpretation:
• Measures alignment between two vectors
• Larger value ⇒ more “pointing in the same direction”

Why we care:
• Many similarity / distance measures reduce to inner products
• If we can compute x · q securely, we can support retrieval securely
```

## The Script:

“Before we talk about cosine or distance, I want to introduce the **dot product** as the core computation.

[PAUSE]

Given two vectors — a database vector **x** and a query vector **q** — the dot product is simply: multiply coordinate-by-coordinate, then sum everything up.

[PAUSE — gesture to interpretation]

Conceptually, it’s an **alignment score**. Bigger dot product means the vectors are more aligned — more semantically similar in embedding space.

[PAUSE]

And here’s the key idea: a lot of similarity and distance objectives in retrieval can be rewritten as **inner products** — sometimes directly, sometimes after small preprocessing.

[PAUSE — transition voice]

So next, let’s connect this to cosine similarity.”

**[CLICK to next slide]**

---

# SLIDE 5: Cosine Similarity Collapses to Dot Product (Normalization)

## Slide Content:

```
Cosine Similarity:
• cos(x, q) = (x · q) / (||x||₂ ||q||₂)

Normalization:
• Define unit vectors:  x̂ = x / ||x||₂   and   q̂ = q / ||q||₂
• Then:  cos(x, q) = x̂ · q̂

CLIP Connection:
• CLIP embeddings are L2-normalized: ||p||₂ = 1
• So similarity is simply:  sim(p, q) = p · q
```

## The Script:

“Cosine similarity is the standard similarity measure used for embeddings.

[PAUSE]

By definition, cosine similarity is the dot product divided by the product of the vector norms.

[PAUSE — point to normalization lines]

Now if we **normalize** both vectors — meaning we force each vector to have length 1 — the denominator becomes 1, and cosine similarity becomes **just the dot product** of the normalized vectors.

[PAUSE — connect back to CLIP]

And with CLIP, we get this for free: CLIP embeddings are already **L2-normalized**. So the similarity score we want is literally just **p dot q**.

[PAUSE — transition voice]

Now the next step is to show something slightly surprising: even Euclidean nearest-neighbor search can collapse to dot products too.”

**[CLICK to next slide]**

---

# SLIDE 6: Euclidean kNN → Dot Product (When Norms Are Fixed)

## Slide Content:

```
k-Nearest Neighbor (kNN) with Euclidean Distance:
• Retrieve x that minimizes ||x − q||₂

Use squared distance (same ranking):
• ||x − q||₂² = ||x||₂² + ||q||₂² − 2(x · q)

If norms are fixed (e.g., unit vectors):
• ||x||₂² is constant over the database
• ||q||₂² is constant for a given query

Ranking equivalence:
• argminₓ ||x − q||₂²   ≡   argmaxₓ (x · q)
```

## The Script:

“Let’s say we do k-nearest neighbors using Euclidean distance: we want the vectors **closest** to the query.

[PAUSE]

We usually work with **squared** Euclidean distance because it gives the same ranking — it just avoids the square root.

[PAUSE — point to expansion]

If we expand the squared distance, we get three terms: the norm of **x**, the norm of **q**, and minus two times the dot product.

[PAUSE]

Now here’s the payoff: if the database vectors all have the **same norm** — and especially if they are **unit vectors** — then those norm terms are constants during ranking.

So minimizing Euclidean distance becomes the same as **maximizing the dot product**.

[PAUSE — transition voice]

But what if we don’t want to assume fixed norms? Then we can still reduce distance to dot product — exactly — by extending the vectors.”

**[CLICK to next slide]**

---

# SLIDE 7: Exact Euclidean Reduction via Vector Extension (Lifting Trick)

## Slide Content:

```
Goal:
• Express squared Euclidean distance as a dot product in higher dimension

Define extended vectors:
• Data vector:   φ(x) = ( ||x||₂² ,  x ,  1 )
• Query vector:  ψ(q) = ( 1 ,  −2q ,  ||q||₂² )

Dot product equals distance:
• φ(x) · ψ(q) = ||x||₂² − 2(x · q) + ||q||₂²
              = ||x − q||₂²

Implication:
• Euclidean kNN can be performed using only dot products (after lifting)
```

## The Script:

“Now we’ll do the exact reduction — no assumptions about fixed norms.

[PAUSE]

We’ll create an **extended** version of each vector. For a database vector **x**, we build φ(x) by concatenating three parts: its squared norm, the vector itself, and a constant 1.

For the query **q**, we build ψ(q) with: a 1, then −2 times the query vector, then the query’s squared norm.

[PAUSE — point to the equality]

When we take the dot product of these extended vectors, it expands to exactly the squared Euclidean distance:
||x||² − 2(x·q) + ||q||².

So **distance** becomes a **single dot product** — just in a slightly larger space.

[PAUSE — transition voice]

At this point, both cosine similarity and Euclidean distance-based kNN are telling us the same story.”

**[CLICK to next slide]**

---

# SLIDE 8: Unifying View — Retrieval Becomes “Dot-Product Search”

## Slide Content:

```
One Primitive, Multiple Objectives:
• Cosine similarity (normalized vectors):  sim(p, q) = p · q
• Euclidean kNN (fixed norms):            argmin ||x − q||² ≡ argmax (x · q)
• Euclidean kNN (general norms):          ||x − q||² = φ(x) · ψ(q)

Practical takeaway:
• We can implement ANN retrieval as:
     “compute many dot products + return top-k”
• So the security target becomes clear: preserve dot-product structure
```

## The Script:

“Here’s the unifying view.

[PAUSE]

Cosine similarity with normalized embeddings is dot product.
Euclidean nearest-neighbor search with normalized data is dot product ranking.
And even without normalization, Euclidean distance can be written **exactly** as a dot product after lifting.

[PAUSE — point to takeaway]

So operationally, retrieval becomes: compute dot products between the query and many candidates, then return the top-k.

[PAUSE]

That means the cryptographic question becomes sharply defined:

Can we let an untrusted server compute these dot products — or their rankings — **without learning what the vectors mean**?

[PAUSE — transition voice]

Now I’ll state precisely what must be preserved, and what leakage we are trying to avoid.”

**[CLICK to next slide]**

---

# SLIDE 9: What the Encrypted Search Must Preserve

## Slide Content:

```
What the server needs to do:
• Given encrypted database vectors and an encrypted query:
   - compute scores consistent with dot products
   - return top-k nearest neighbors (ANN)

What must remain hidden:
• Contents of database vectors
• Contents of queries
• Sensitive relationships (e.g., similarity structure) beyond what is unavoidable

Design target (from the math):
• Enable distance / similarity search by supporting:
   - inner-product evaluation, or
   - inner-product–consistent ranking
```

## The Script:

“Now we can clearly state the computational requirement.

[PAUSE]

The server doesn’t need to ‘understand images’ — it needs to compute **scores** that behave like dot products and produce the correct top-k retrieval results.

[PAUSE — gesture to hidden items]

At the same time, we want to hide the content of the database vectors, hide the content of the query, and avoid leaking similarity structure beyond what’s fundamentally unavoidable for search.

[PAUSE]

And because we just reduced cosine similarity and Euclidean distance search to dot products, our design target is straightforward:

We need an encrypted-domain mechanism that supports **inner-product evaluation** or at least **inner-product–consistent ranking**.

[PAUSE — transition voice]

Now let me show our first secure scheme — **ASPE** — and how it achieves this through selective scalar-product preservation.”

**[CLICK to next slide]**

---

# SLIDE 10: ASPE — Overview

## Slide Content:

```
Asymmetric Scalar Product-Preserving Encryption (Wong et al., 2009)

Design Principle:
• Selectively preserves ONLY scalar products necessary for distance comparison

Scalar Product Classification:
┌──────────┬─────────────────────────────────┬─────────────┐
│ Type     │ Relationship                    │ Preserved?  │
├──────────┼─────────────────────────────────┼─────────────┤
│ Type-1   │ Database · Database (pᵢ · pⱼ)   │ ✗ Concealed │
│ Type-2   │ Database · Query (pᵢ · q)       │ ✓ Preserved │
│ Type-3   │ Query · Query (q · q)           │ ✗ Concealed │
└──────────┴─────────────────────────────────┴─────────────┘
```

## The Script:

"ASPE stands for **Asymmetric Scalar Product-Preserving Encryption**. It was introduced by Wong and colleagues in 2009, and it is specifically designed for secure nearest neighbor search.

[PAUSE]

The key idea — and this is elegant — is **selective preservation**.

[PAUSE — gesture to table]

Look at this table. There are three types of scalar products we might compute:

**Type-1**: comparing two database points with each other.
**Type-2**: comparing a database point with a query.
**Type-3**: comparing a query with itself.

[PAUSE]

ASPE **conceals** Type-1 and Type-3 — this prevents an attacker from reconstructing the database or inferring query content.

But it **preserves** Type-2 — and this is *exactly* what we need for similarity search. We can compare queries to database points without revealing anything else.

[PAUSE — transition voice]

Now let me show you **how** ASPE achieves this, starting with how it transforms the vectors."

**[CLICK to next slide]**

---

# SLIDE 11: ASPE — Vector Extension

## Slide Content:

```
Dimension Augmentation:
• Original vectors p, q ∈ ℝᵈ are extended to ℝᵈ⁺¹

Database Vector Extension:
   p̂ = [p₁, p₂, ..., pᵈ, -½||p||²]ᵀ ∈ ℝᵈ⁺¹

Query Vector Extension:
   q̂ = [r·q₁, r·q₂, ..., r·qᵈ, r]ᵀ ∈ ℝᵈ⁺¹
   
   where r > 0 is a random positive scalar (fresh for each query)

Extended Scalar Product:
   p̂ · q̂ = r(p · q) − (r/2)||p||²
         = r(p · q − ½||p||²)
```

## The Script:

"The first step in ASPE is vector extension.

[PAUSE]

We take our original d-dimensional vectors and extend them to d plus one dimensions.

[PAUSE — point to database formula]

For database vectors, we append a special value: negative one-half times the squared norm of the vector.

[PAUSE — point to query formula]

For query vectors, we multiply the entire vector by a random positive scalar r, and then append r as the final coordinate. Importantly, r is chosen freshly for each query.

[PAUSE — point to result]

Now, when we compute the scalar product of these extended vectors, the factor r scales the entire result. We get r times the quantity: p dot q minus one-half the squared norm of p.

[PAUSE]

Because r is positive, it scales the values but preserves their relative order, which is exactly what we need for ranking.

[PAUSE — transition voice]

But we cannot send these extended vectors directly to the server. We need to encrypt them. That is where the matrix transformation comes in."

**[CLICK to next slide]**

---

# SLIDE 12: ASPE — Matrix Transformation

## Slide Content:

```
Secret Key Generation:
• Generate random invertible matrix M ∈ ℝ⁽ᵈ⁺¹⁾ˣ⁽ᵈ⁺¹⁾
• Matrix M is the secret key K

Encryption Functions:

   Database Encryption:    p' = Mᵀ · p̂
   
   Query Encryption:       q' = M⁻¹ · q̂

Scalar Product Preservation Proof:

   p' · q' = (Mᵀp̂)ᵀ · (M⁻¹q̂)
           = p̂ᵀ M M⁻¹ q̂
           = p̂ᵀ q̂
           = p̂ · q̂  ✓
```

## The Script:

"Here is the core mechanism of ASPE.

[PAUSE]

The secret key is simply a **large, random, invertible matrix** M — with dimensions d plus one by d plus one.

[PAUSE — point to encryption functions]

Now, watch carefully. Database vectors and query vectors are encrypted **differently**:

For **database** vectors, we multiply by **M transpose**.
For **query** vectors, we multiply by **M inverse**.

[PAUSE]

This asymmetry is *deliberate* — and it is why the scheme is called **Asymmetric** Scalar Product-Preserving Encryption.

[PAUSE — point to proof]

Let me show you why this works. When we compute the scalar product of the encrypted vectors:

We have M transpose p-hat, dotted with M inverse q-hat.
Taking the transpose and rearranging, we get p-hat transpose, times M, times M inverse, times q-hat.

[PAUSE — emphasize]

And here is the key: **M times M inverse equals the identity matrix**. They cancel out.

So we are left with just **p-hat dot q-hat** — the original extended scalar product, perfectly preserved.

[PAUSE — transition voice]

And this preserved scalar product is exactly what lets us compare distances in the encrypted domain."

**[CLICK to next slide]**

---

# SLIDE 13: ASPE — Distance Comparison in Encrypted Domain

## Slide Content:

```
Encrypted Comparison Protocol:
• Given encrypted database points p'₁, p'₂ and encrypted query q':

   (p'₁ − p'₂) · q' > 0  ⟺  d(p₂, q) > d(p₁, q)

Derivation:
   (p'₁ − p'₂) · q' = p'₁ · q' − p'₂ · q'
                    = p̂₁ · q̂ − p̂₂ · q̂
                    
Expanding:
   = r(p₁ · q − ½||p₁||²) − r(p₂ · q − ½||p₂||²)
   = r [ (p₁ − p₂) · q + ½(||p₂||² − ||p₁||²) ]

This is the standard distance comparison criterion (scaled by r).
```

## The Script:

"So how do we actually use this for search?

[PAUSE — point to main formula]

Here is the protocol. Given two encrypted database points and an encrypted query, we compute this expression: p-prime-one minus p-prime-two, dotted with q-prime.

If the result is positive, then p-two is farther from the query than p-one.
If the result is negative, then p-one is farther.

[PAUSE]

In other words, we can determine which database point is closer to the query — without decrypting anything.

[PAUSE — gesture to derivation]

The derivation is shown here. Because scalar products are preserved, this encrypted comparison reduces to the standard distance comparison criterion, just scaled by the random factor r.

[PAUSE]

Since r is positive, it doesn't flip the sign. The server can rank all database points by distance to the query correctly.

[PAUSE — slower, transition voice]

Now... ASPE is elegant. And it works. But it has limitations that motivated me to explore a different approach.

Let me explain."

**[CLICK to next slide]**

---

# SLIDE 14: Why ASPE Fails Under Level-3 (Known-Plaintext) Attacks

## Slide Content:

```
Core weakness:
• ASPE is a linear, deterministic matrix transformation

Database encryption (deterministic):
• p' = Mᵀ p̂
• If attacker knows plaintext p ⇒ can compute extended plaintext p̂

Key recovery from known pairs:
• Collect (d+1) linearly independent plaintext-ciphertext pairs:
     (p̂₁, p'₁), (p̂₂, p'₂), ..., (p̂_{d+1}, p'_{d+1})

• Stack them as matrices:
     P̂ = [p̂₁ … p̂_{d+1}]    and    P' = [p'₁ … p'_{d+1}]

• Then:
     P' = Mᵀ P̂   ⇒   Mᵀ = P' (P̂)⁻¹

Consequence:
• Recover M ⇒ decrypt database vectors and break privacy
• Random r in queries does NOT fix this (database lane already leaks M)
```

**[CLICK to next slide]**

---

# SLIDE 15: Motivation for Lattice-Based Approaches

## Slide Content:

```
ASPE Limitations for Cloud Deployment:

1. Deterministic encryption → leaks statistical patterns over large databases

2. Vulnerable to Level-3 attacks (known-plaintext attacks)
   • If attacker obtains plaintext-ciphertext pairs, key can be recovered

3. No post-quantum security guarantees

Alternative Direction — Lattice-Based Cryptography:
• Provable security reductions to hard mathematical problems
• Resistance to quantum attacks
• Foundation: Learning With Errors (LWE) problem
```

## The Script:

"ASPE has three significant limitations.

[PAUSE — count on fingers]

**First**: the encryption is deterministic. The same input always produces the same output. Over a large database, this leaks statistical patterns that an attacker can exploit.

**Second**: ASPE is vulnerable to what we call **Level-3 attacks** — known-plaintext attacks. If an attacker somehow obtains even a few pairs of original vectors and their encrypted versions, they can **recover the secret key**. In a cloud environment with multiple users, this is a serious concern.

**Third**: there are no post-quantum security guarantees. As quantum computers advance, ASPE offers no protection.

[PAUSE — transition voice, slightly slower]

These limitations led me to investigate a fundamentally different approach: **lattice-based cryptography**.

[PAUSE]

Lattice-based schemes offer provable security — meaning we can mathematically prove that breaking the encryption is as hard as solving problems that have resisted attack for decades. They are also believed to be **resistant to quantum computers**.

[PAUSE]

The foundation of this approach is something called the **Learning With Errors** problem — LWE for short.

Let me walk you through it."

**[CLICK to next slide]**

---

# SLIDE 16: LWE — The Hardness Foundation

## Slide Content:

```
The Problem with Exact Linear Systems:

Consider recovering secret vector s = [x, y, z, w]ᵀ from:

   10x + 5y + 2z − 3w = 154
   −2x + 12y + 0z + 8w = 320

In matrix form: As = b

Vulnerability:
• Standard system of linear equations
• Solvable instantly via Gaussian elimination
• Complexity: O(n³)

Conclusion:
• Exact equations CANNOT hide the secret — system is trivially invertible
```

## The Script:

"To understand why LWE is hard, let us first see why **ordinary** linear equations are **easy**.

[PAUSE — point to equations]

Suppose I have a secret vector s with four components: x, y, z, w. And I give you these two equations.

[PAUSE]

Now, if you remember your linear algebra, this is just a system of linear equations. In matrix form: **A times s equals b**.

[PAUSE — emphasize]

Any computer can solve this **instantly**. Gaussian elimination. Matrix inversion. The complexity is just O of n cubed — polynomial time.

[PAUSE]

So if I tried to use exact linear equations to hide my secret key, I would fail completely. You would recover s in milliseconds.

[PAUSE — transition voice]

The question is: can we modify this system to make it **hard**?

[PAUSE]

The answer is yes — and the modification is surprisingly simple."

**[CLICK to next slide]**

---

# SLIDE 17: LWE — Introducing Computational Hardness

## Slide Content:

```
The LWE Modification:
• Add small random ERROR term eᵢ to each equation:

   ⟨aᵢ, s⟩ + eᵢ = bᵢ

Parameters:
• aᵢ ∈ ℤqⁿ — random coefficient vector
• s ∈ ℤqⁿ — secret vector  
• eᵢ ← χ — sampled from error distribution (small, close to 0)
• All operations mod q

Formal Definition (Decision-LWE):
Given m samples (aᵢ, bᵢ), distinguish between:
   1. bᵢ = ⟨aᵢ, s⟩ + eᵢ (mod q)  — structured (has hidden secret)
   2. bᵢ ← ℤq uniformly random    — purely random

This is believed to be computationally infeasible.
```

## The Script:

"Here is the LWE modification.

[PAUSE — point to equation]

Instead of exact equations, we add a small **random error** term — e-i — to each equation.

[PAUSE]

The error is sampled from a distribution that produces values **close to zero** — small integers like negative 2, negative 1, 0, 1, 2.

[PAUSE]

Also, everything is computed **modulo q** — a large integer. This adds another layer of complexity.

[PAUSE — point to definition]

The formal problem is called **Decision-LWE**, and it asks: given many of these noisy equations, can you tell whether they hide a secret vector s, or whether they are just **random noise**?

[PAUSE — emphasize]

The remarkable fact is: **no one knows how to do this efficiently**. Not classical computers. Not quantum computers. The best known algorithms take **exponential time**.

[PAUSE — transition voice]

Let me make this concrete with a numerical example."

**[CLICK to next slide]**

---

# SLIDE 18: LWE — Numerical Example

## Slide Content:

```
Setup:
• Modulus: q = 89
• Secret vector: s = [x, y, z, w]ᵀ (unknown to attacker)

Without Errors (Trivially Solvable):
   10x + 5y + 2z − 3w ≡ 154 (mod 89)
   −2x + 12y + 0z + 8w ≡ 320 (mod 89)
   → Solve with Gaussian elimination ✓

With Errors (Computationally Hard):
   10x + 5y + 2z − 3w + 2 ≡ 156 (mod 89)    [e₁ = +2]
   −2x + 12y + 0z + 8w − 2 ≡ 318 (mod 89)   [e₂ = −2]

The Attacker's Dilemma:
• Observes only (156, 318, ...) — not the true (154, 320, ...)
• Cannot separate "signal" from "noise"
• Modular arithmetic prevents approximation techniques
```

## The Script:

"Let us work through a concrete example.

[PAUSE]

Suppose our modulus q is 89, and we have a secret vector s that the attacker wants to recover.

[PAUSE — point to first system]

**Without errors**, the attacker sees these equations. They give the exact values 154 and 320. As I said, Gaussian elimination solves this instantly.

[PAUSE — point to second system]

**With errors**, we add small noise. Here, e-one equals **plus 2**, and e-two equals **minus 2**. Now the attacker sees 156 and 318 instead.

[PAUSE — emphasize]

Here is the attacker's dilemma. They see 156. But is that because the true answer was 154 plus an error of 2? Or was the true answer 155 plus an error of 1? Or 156 plus an error of 0?

[PAUSE]

They **cannot tell**. They cannot separate the signal from the noise. And the modular arithmetic — the wrapping around at 89 — prevents them from using approximation or rounding techniques.

[PAUSE — slower]

Give them a thousand equations with small errors, and they **still** cannot recover s. This is the hardness of LWE.

[PAUSE — transition voice]

Now let me show you how we build an encryption scheme on top of this."

**[CLICK to next slide]**

---

# SLIDE 19: LWE — Key Generation

## Slide Content:

```
Public Key Generation (Alice):

1. Secret Key: Sample s ← ℤqⁿ uniformly at random

2. Public Matrix: Generate A ← ℤqᵐˣⁿ uniformly at random

3. Error Vector: Sample e ← χᵐ from error distribution

4. Public Vector: Compute b = As + e (mod q)

Key Distribution:
• Secret Key: SK = s
• Public Key: PK = (A, b)

Security Basis:
• Public key (A, b) is computationally indistinguishable from (A, u)
  where u is uniformly random
• This follows directly from the LWE assumption
```

## The Script:

"Let me walk you through key generation step by step.

[PAUSE]

Alice — the data owner — starts by sampling a **secret vector s** uniformly at random from integers mod q.

[PAUSE]

Next, she generates a large **random matrix A**. This will be public.

[PAUSE]

Then — and this is crucial — she samples an **error vector e** from the error distribution. Small random values.

[PAUSE — point to computation]

Finally, she computes **b equals A times s, plus e, mod q**.

[PAUSE]

The **secret key** is just s.
The **public key** is the pair: the matrix A, and the vector b.

[PAUSE — point to security basis]

Why is this secure? Because by the LWE assumption, the pair (A, b) is **indistinguishable** from (A, u) where u is just random noise. An attacker looking at the public key cannot tell that there is a hidden structure — a hidden secret s — underneath.

[PAUSE — transition voice]

Now let us see how Bob uses this public key to encrypt a message."

**[CLICK to next slide]**

---

# SLIDE 20: LWE — Encryption Protocol

## Slide Content:

```
Objective: Bob encrypts a single bit μ ∈ {0, 1} for Alice

Step 1 — Subset Selection and Aggregation:
• Sample random binary vector r ← {0, 1}ᵐ
• Compute:
     u = Aᵀr ∈ ℤqⁿ
     v' = bᵀr = ⟨b, r⟩ ∈ ℤq

Step 2 — Message Encoding:
• Encode the bit μ:
     v = v' + μ · ⌊q/2⌋ (mod q)

Ciphertext: CT = (u, v)

Intuition:
• If μ = 0: v ≈ ⟨u, s⟩ + esum
• If μ = 1: v ≈ ⟨u, s⟩ + esum + ⌊q/2⌋
```

## The Script:

"For encryption, let us say Bob wants to send a single bit — zero or one — to Alice.

[PAUSE]

**Step one**: Bob randomly selects a subset of Alice's public equations. Mathematically, he samples a binary vector r — zeros and ones — and uses it to create weighted sums.

He computes **u** as A-transpose times r.
And **v-prime** as b-transpose times r — essentially summing up selected entries of b.

[PAUSE — point to step 2]

**Step two**: Bob encodes his message bit. If he is sending **zero**, he uses v-prime as is. If he is sending **one**, he adds **half the modulus** — floor of q over 2 — to v-prime.

[PAUSE]

The ciphertext is just the pair: u and v.

[PAUSE — point to intuition]

Here is the intuition. Because of how the public key was constructed, v encodes either a value **close to zero** if the bit is zero, or a value **close to half the modulus** if the bit is one. The accumulated errors keep it from being exact — but the gap is large enough to distinguish.

[PAUSE — transition voice]

Let me show you how Alice decrypts."

**[CLICK to next slide]**

---

# SLIDE 21: LWE — Decryption Protocol

## Slide Content:

```
Input: Alice receives ciphertext CT = (u, v)

Decryption Computation:
   Δ = v − ⟨u, s⟩ (mod q)

Analysis:
   Δ = (⟨b, r⟩ + μ · ⌊q/2⌋) − ⟨Aᵀr, s⟩
     = ⟨As + e, r⟩ + μ · ⌊q/2⌋ − ⟨Aᵀr, s⟩
     = ⟨e, r⟩ + μ · ⌊q/2⌋
     = esum + μ · ⌊q/2⌋

Decision Rule:
• If Δ close to 0 (|Δ| < q/4):     Output μ = 0
• If Δ close to q/2 (|Δ − q/2| < q/4):  Output μ = 1

Example (q = 89, ⌊q/2⌋ = 44):
• Δ ∈ {0,1,...,22} ∪ {67,...,88} → decode as 0
• Δ ∈ {23,...,66} → decode as 1
```

## The Script:

"Alice receives the ciphertext — the pair u and v.

[PAUSE]

She computes **delta**: v minus the inner product of u with her **secret key s**.

[PAUSE — point to analysis]

Let me walk through the algebra. We substitute the definitions... expand... and notice that the A-s terms **cancel out**.

[PAUSE — emphasize]

What remains is just: **e-sum** — the accumulated error — **plus** mu times floor of q over 2.

[PAUSE — point to decision rule]

So if the original bit was **zero**, delta is just the small error — close to zero.
If the original bit was **one**, delta is the small error **plus 44** — close to half of 89.

[PAUSE]

The error is small — maybe plus or minus 5. So Alice can easily distinguish: values near zero mean bit zero; values near 44 mean bit one.

[PAUSE — gesture to example]

In our example with q equals 89, anything below 22 or above 67 decodes as zero. Anything in the middle decodes as one.

[PAUSE — transition voice]

Now, this shows LWE encryption for a **single bit**. For my research, I need to encrypt **high-dimensional image features**. And that brings us to a key challenge."

**[CLICK to next slide]**

---

# SLIDE 22: Integer Quantization Challenge

## Slide Content:

```
The Integration Problem:
• CLIP embeddings are floating-point: p ∈ ℝᵈ with ||p||₂ = 1
• LWE requires integer arithmetic: p ∈ ℤqᵈ

Quantization Procedure:

1. Scaling: Multiply by precision parameter γ
      p̃ᵢ = γ · pᵢ

2. Rounding: Convert to integers
      p̂ᵢ = ⌊p̃ᵢ⌉ ∈ ℤ

3. Modular Reduction: Map to ℤq
      p'ᵢ = p̂ᵢ (mod q)

Trade-off:
• Larger γ → Higher precision, but larger ciphertexts
• Smaller γ → More quantization error, retrieval accuracy loss
```

## The Script:

"Here is a central challenge I am currently working on.

[PAUSE]

CLIP embeddings are **floating-point numbers** — real values between negative one and one.

But LWE encryption requires **integers**. All the arithmetic happens in Z-q — integers modulo q.

[PAUSE — point to procedure]

So I need a **quantization procedure** to bridge this gap.

[PAUSE]

**Step one**: Scale the embedding by a precision parameter **gamma**. If my original value is 0.75 and gamma is 1000, I get 750.

**Step two**: Round to the nearest integer.

**Step three**: Reduce modulo q to fit within the finite field.

[PAUSE — point to trade-off]

The challenge is the **trade-off**. A larger gamma gives me more precision — I can distinguish 0.751 from 0.752. But it also means larger numbers, larger ciphertexts, and more noise accumulation in the encryption.

A smaller gamma means more quantization error — I might round 0.751 and 0.759 to the same integer, losing retrieval accuracy.

[PAUSE — transition voice]

The critical question is: does this quantization preserve the similarity relationships we need for search?

Let me address that."

**[CLICK to next slide]**

---

# SLIDE 23: Preserving Cosine Similarity Under Quantization

## Slide Content:

```
Original Cosine Similarity (Normalized Vectors):
   sim(p, q) = p · q = Σᵢ pᵢqᵢ

Quantized Inner Product:
   sim(p̂, q̂) = Σᵢ p̂ᵢq̂ᵢ = Σᵢ ⌊γpᵢ⌉ · ⌊γqᵢ⌉

Error Analysis:
• Let εᵢ = p̂ᵢ − γpᵢ (rounding error, |εᵢ| ≤ 0.5)
• Quantized product expands to:

   p̂ · q̂ = γ²(p · q) + γΣᵢ(pᵢδᵢ + qᵢεᵢ) + Σᵢεᵢδᵢ
            \_____/   \__________________/   \_____/
            scaled      cross terms         noise
            similarity

Ranking Preservation Condition:
   sign(sim(p₁,q) − sim(p₂,q)) = sign(sim(p̂₁,q̂) − sim(p̂₂,q̂))
   
• Holds when quantization error << similarity gap between candidates
```

## The Script:

"Let me show you the mathematical analysis.

[PAUSE — point to original]

The original cosine similarity is just the sum of products: p-i times q-i.

[PAUSE — point to quantized]

After quantization, we are computing the sum of **rounded** products.

[PAUSE — point to error analysis]

Let epsilon-i be the rounding error for each component — bounded by plus or minus 0.5.

When we expand the quantized inner product, we get **three terms**:

First, **gamma squared times the original similarity** — this is the signal we want.

Second, **cross terms** that mix the original values with the rounding errors.

Third, pure **noise** — products of rounding errors with each other.

[PAUSE — point to condition]

For **ranking preservation** — which is what we need for k-NN search — we need the **sign** of the similarity difference to be preserved.

[PAUSE — emphasize]

This holds when the quantization error is **small compared to the gap** between candidates. If two images have very different similarities to the query, quantization will not flip their ranking. But if two images have almost identical similarities, quantization might introduce errors.

[PAUSE — transition voice]

With this understanding, let me show you how all the pieces fit together in my proposed scheme."

**[CLICK to next slide]**

---

# SLIDE 24: Proposed Scheme — High-Level Architecture

## Slide Content:

```
┌─────────────────────────────────────────────────────────────┐
│                      DATA OWNER                             │
│  Image → CLIP → Normalize → Quantize → LWE Encrypt          │
│                                    ↓                        │
│                          Encrypted Database                 │
└─────────────────────────────────────────────────────────────┘
                              ↓ Upload
┌─────────────────────────────────────────────────────────────┐
│                      CLOUD SERVER                           │
│  Stores: { E(p̂₁), E(p̂₂), ..., E(p̂ₙ) }                       │
│  Receives: E(q̂)                                             │
│  Computes: Encrypted similarity scores                      │
│  Returns: Top-k encrypted indices                           │
└─────────────────────────────────────────────────────────────┘
                              ↑ Query
┌─────────────────────────────────────────────────────────────┐
│                      QUERY USER                             │
│  Query Image → CLIP → Normalize → Quantize → LWE Encrypt    │
│                                    ↓                        │
│                              E(q̂) → Server                  │
└─────────────────────────────────────────────────────────────┘
```

## The Script:

"Here is how the complete system works.

[PAUSE — point to top box]

The **data owner** takes each image, extracts the CLIP embedding, normalizes it, **quantizes** it to integers, and then applies **LWE encryption**. The encrypted database is uploaded to the cloud.

[PAUSE — point to middle box]

The **cloud server** stores all these encrypted vectors. It never sees the original images or features — only ciphertexts.

[PAUSE — point to bottom box]

When a **user** wants to search, they follow the same pipeline: CLIP, normalize, quantize, LWE encrypt. They send their encrypted query to the server.

[PAUSE — gesture across all boxes]

The server computes encrypted similarity scores — using the LWE structure to perform comparisons in the encrypted domain — and returns the indices of the top-k results.

[PAUSE]

At **no point** does the server learn the image content, the query content, or the true similarity values. It operates entirely on encrypted data.

[PAUSE — transition voice]

Now let me summarize why this LWE-based approach is superior to ASPE."

**[CLICK to next slide]**

---

# SLIDE 25: Security Analysis — Comparison

## Slide Content:

```
┌─────────────────────────────────┬──────────────┬──────────────┐
│ Attack Type                     │     ASPE     │  LWE-Based   │
├─────────────────────────────────┼──────────────┼──────────────┤
│ Ciphertext-only (Level-1)       │  ✓ Secure    │  ✓ Secure    │
│ Known-sample (Level-2)          │  ✓ Secure    │  ✓ Secure    │
│ Known-plaintext (Level-3)       │ ✗ Vulnerable │  ✓ Secure    │
│ Quantum Adversary               │ ✗ Vulnerable │  ✓ Secure    │
└─────────────────────────────────┴──────────────┴──────────────┘

LWE Security Foundation:
• Breaking scheme → Solving Decision-LWE
• Solving Decision-LWE → Solving worst-case lattice problems (GapSVP, SIVP)
• Best known attacks: 2^O(n) — exponential in dimension
• No efficient quantum algorithm known
```

## The Script:

"Let me make the comparison explicit.

[PAUSE — point to table row by row]

Against **ciphertext-only attacks** — where the adversary only sees encrypted data — both schemes are secure.

Against **known-sample attacks** — where the adversary has some plaintext-ciphertext pairs from a *different* key — both schemes are secure.

[PAUSE — emphasize]

But against **known-plaintext attacks** — where the adversary has pairs from the *same* key — ASPE **fails**. The key can be recovered. The LWE-based scheme **remains secure**.

And against **quantum adversaries** — ASPE offers no protection, while LWE is believed to be **quantum-resistant**.

[PAUSE — point to foundation]

The security of LWE reduces to well-studied lattice problems. Breaking LWE means solving problems like the **Shortest Vector Problem** — and the best known algorithms, classical or quantum, take **exponential time** in the dimension.

[PAUSE — transition voice]

Let me now summarize where my research stands."

**[CLICK to next slide]**

---

# SLIDE 26: Research Progress Summary

## Slide Content:

```
Completed:
✓ Comprehensive literature review on privacy-preserving CBIR
✓ Implementation and validation of ASPE scheme
✓ Theoretical analysis of LWE-based constructions
✓ Investigation of CLIP embedding properties

In Progress:
→ Integer quantization methods preserving cosine similarity
→ Security analysis grounded in LWE hardness assumption
→ Drafting research proposal with formal problem definition

Planned:
○ Prototype implementation on benchmark datasets (UKBench, Oxford 5K)
○ Empirical evaluation of accuracy vs. security parameters
○ Paper submission
```

## The Script:

"Let me summarize my progress.

[PAUSE — point to completed]

I have **completed** a comprehensive literature review. I have **implemented and validated** the ASPE scheme to understand its mechanics and limitations firsthand. I have developed a **theoretical understanding** of LWE-based constructions, as I have presented today. And I have investigated the specific properties of CLIP embeddings relevant to cryptographic integration.

[PAUSE — point to in progress]

I am **currently** working on the integer quantization methods — how to convert floating-point embeddings to integers while preserving similarity rankings. I am conducting security analysis to formally ground my scheme in the LWE hardness assumption. And I am actively **drafting my research proposal** with a precise problem definition.

[PAUSE — point to planned]

**Next**, I will build a prototype and evaluate it on standard benchmarks — UKBench and Oxford 5K — measuring the trade-off between retrieval accuracy and security parameters.

[PAUSE — look at audience]

That concludes my technical presentation."

**[CLICK to next slide]**

---

# SLIDE 27: References

## Slide Content:

```
References:

1. Wong, W. K., Cheung, D. W., Kao, B., & Mamoulis, N. (2009). 
   Secure kNN computation on encrypted databases. SIGMOD.

2. Regev, O. (2009). On lattices, learning with errors, random 
   linear codes, and cryptography. Journal of the ACM, 56(6).

3. Radford, A., et al. (2021). Learning transferable visual models 
   from natural language supervision. ICML.

4. NIST Post-Quantum Cryptography Standardization (2024).
```

## The Script:

"These are the key references underlying my presentation.

[PAUSE — only if asked]

Wong et al. for ASPE. Regev's foundational paper on LWE. Radford et al. for CLIP. And the NIST post-quantum standards that validate the practical relevance of lattice-based cryptography."

**[CLICK to next slide]**

---

# SLIDE 28: Questions

## Slide Content:

```
Questions & Discussion



Eng: Ahmed Mohamed Elsayed

Thank you for your attention.
```

## The Script:

"Thank you for your attention.

[PAUSE — look around the room]

I am happy to take any questions."

---

# HANDLING COMMON QUESTIONS

## If asked: "What is the main contribution of your research?"

"The main contribution I am working toward is a **practical LWE-based scheme** for secure image retrieval that addresses the limitations of existing approaches like ASPE — specifically, providing security against known-plaintext attacks and post-quantum adversaries, while maintaining acceptable retrieval accuracy through careful quantization of CLIP embeddings."

---

## If asked: "What are the limitations of your approach?"

"There are two main challenges I am still addressing. First, the **quantization introduces error**, so there is a trade-off between precision and efficiency that I am working to optimize. Second, LWE-based encryption has **higher computational overhead** than ASPE, so I am investigating ways to reduce dimension and improve efficiency while maintaining security."

---

## If asked: "Why CLIP specifically?"

"CLIP provides **state-of-the-art semantic representations** for images. More importantly for my work, CLIP embeddings are **normalized**, which means cosine similarity reduces to a simple inner product. This simplifies the cryptographic protocol significantly, as I only need to preserve inner products rather than more complex distance metrics."

---

## If asked about the qualification exam delay:

"The delay was due to departmental scheduling. However, it gave me additional time to deepen my technical investigation — particularly the quantization challenge and LWE security analysis that I presented today. I am now prepared to proceed with the examination this semester."
